{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    " \n",
    "# cap = cv2.VideoCapture(0)   # 0: default camera\n",
    "# #cap = cv2.VideoCapture(\"test.mp4\") #동영상 파일에서 읽기\n",
    " \n",
    "# while cap.isOpened():\n",
    "#     # 카메라 프레임 읽기\n",
    "#     success, frame = cap.read()\n",
    "#     if success:\n",
    "#         # 프레임 출력\n",
    "#         cv2.imshow('Camera Window', frame)\n",
    " \n",
    "#         # ESC를 누르면 종료\n",
    "#         key = cv2.waitKey(1) & 0xFF\n",
    "#         if (key == 27): \n",
    "#             break\n",
    " \n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-oe0iat4a/opencv/modules/objdetect/src/cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-68c7070e11fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#인식된 얼굴 갯수를 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-oe0iat4a/opencv/modules/objdetect/src/cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "\n",
    "# #웹캠에서 영상을 읽어온다\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap.set(3, 640) #WIDTH\n",
    "# cap.set(4, 480) #HEIGHT_\n",
    "\n",
    "# #얼굴 인식 캐스케이드 파일 읽는다\n",
    "# face_cascade = cv2.CascadeClassifier('/Users/yejoonko/git/Project/smart_mirror_small_test/opencv-master/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# while(True):\n",
    "#     # frame 별로 capture 한다\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "#     #인식된 얼굴 갯수를 출력\n",
    "# #     print(len(faces))\n",
    "\n",
    "#     # 인식된 얼굴에 사각형을 출력한다\n",
    "#     for (x,y,w,h) in faces:\n",
    "#          cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "\n",
    "#     #화면에 출력한다\n",
    "#     cv2.imshow('webCamera',frame)\n",
    "#     # 종료가 이상하게 안됨..\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "        \n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#pip install opencv-python\n",
    "import cv2\n",
    "import datetime\n",
    "#노트북 카메라에서 영상을 읽어온다\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "#얼굴 인식 캐스케이드 파일 읽는다\n",
    "face_cascade = cv2.CascadeClassifier('/Users/yejoonko/git/Project/smart_mirror_small_test/opencv-master/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "count = 0\n",
    "now = datetime.datetime.now().strftime(\"%b_%d_%H-%M-%S\")    \n",
    "flag = 0\n",
    "while(True):\n",
    "    # frame 별로 capture 한다\n",
    "    ret, frame = cap.read()\n",
    "    # 좌우 반전은 1, 상하반전은 0\n",
    "    frame = cv2.flip(frame,1)\n",
    "    # 프레임이 제대로 읽어지지 않은 경우\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "        \n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #detectMultiScale (InputArray image, std::vector< Rect > &objects, double scaleFactor=1.1, int minNeighbors=3, int flags=0, Size minSize=Size(), Size maxSize=Size())\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.2, 5)\n",
    "    \n",
    "    # 빨간 사각형으로 인식된 얼굴은 표시한다.\n",
    "    if len(faces) > 0 and flag == 0:\n",
    "        cv2.IMREAD_UNCHANGED\n",
    "        cv2.imwrite(\"/Users/yejoonko/git/Project/smart_mirror_small_test/face/data/cap_\"+str(count) + \".png\", frame)\n",
    "        count += 1\n",
    "        print(count)\n",
    "        if count == 5 :\n",
    "            flag = 1\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    #webCamera라는 이름으로 실시간 화면을 보여준다.\n",
    "    cv2.imshow('webCamera',frame)\n",
    "    # q를 누르면 종료되도록 하는 코드이다.\n",
    "    \n",
    "    key = cv2.waitKey(33)  # 1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "#     elif key == ord('c'):  \n",
    "#         cv2.IMREAD_UNCHANGED\n",
    "#         cv2.imwrite(\"/Users/yejoonko/git/Project/smart_mirror_small_test/face/data/cap\"+str(count) + \".png\", frame)\n",
    "#         count += 1\n",
    "        \n",
    "# 메모리를 해제시켜준다.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# This key will serv/e all examples in this document.\n",
    "KEY = os.getenv(\"AZURE_KEY\")\n",
    "\n",
    "# This endpoint will be used in all examples in this quickstart.\n",
    "ENDPOINT = os.getenv(\"AZURE_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gender': 'female', 'age': 22.0, 'emotion': {'anger': 0.0, 'contempt': 0.013, 'disgust': 0.0, 'fear': 0.0, 'happiness': 0.005, 'neutral': 0.979, 'sadness': 0.003, 'surprise': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "# 나이, 성별찾아주는 친구\n",
    "# pip install cognitive_face\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "import cognitive_face as CF\n",
    "#pip install cognitive_face\n",
    "\n",
    "CF.Key.set(KEY)\n",
    "\n",
    "BASE_URL = 'https://koreacentral.api.cognitive.microsoft.com/face/v1.0/' # 자신의 지역에 해당하는 URL\n",
    "CF.BaseUrl.set(BASE_URL)\n",
    "\n",
    "img_url = '/Users/yejoonko/git/Project/smart_mirror_small_test/face/data/cap_4.png' # 이미지 파일의 경로\n",
    "faces = CF.face.detect(img_url,True,False,'age,gender,emotion') # 중요!\n",
    "# detect 함수는 4가지의 매개변수를 갖는다.\n",
    "# 첫 번째 인자 : 이미지파일\n",
    "# 두 번째 인자 : face_id의 반환 여부\n",
    "# 세 번째 인자 : landmarks(눈,코,입 등의 위치)의 반환 여부\n",
    "# 네 번째 인자 : 반환할 속성(연령,성별 등)\n",
    "\n",
    "for face in faces:\n",
    "    print(face['faceAttributes']) # 터미널 창에 속성값들을 출력\n",
    "\n",
    "# 인식된 얼굴에 네모 박스 그리는 함수 작성\n",
    "def getRectangle(faceDictionary):\n",
    "    rect = faceDictionary['faceRectangle']\n",
    "    left = rect['left']\n",
    "    top = rect['top']\n",
    "    bottom = left + rect['height']\n",
    "    right = top + rect['width']\n",
    "    return ((left, top), (bottom, right))\n",
    "\n",
    "img = Image.open(img_url) # img 변수에 이미지 파일을 넣어준다.\n",
    "draw = ImageDraw.Draw(img)\n",
    "for face in faces:\n",
    "    draw.rectangle(getRectangle(face), outline='red',width=5) # 인식된 얼굴들에 네모 박스 쳐주기\n",
    "\n",
    "img.show() # 이미지 뷰어로 이미지 띄우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'gender': 'female', 'age': 18.0, 'emotion': {'anger': 0.0, 'contempt': 0.006, 'disgust': 0.0, 'fear': 0.0, 'happiness': 0.0, 'neutral': 0.981, 'sadness': 0.013, 'surprise': 0.0}}, {'gender': 'female', 'age': 18.0, 'emotion': {'anger': 0.0, 'contempt': 0.006, 'disgust': 0.0, 'fear': 0.0, 'happiness': 0.0, 'neutral': 0.981, 'sadness': 0.013, 'surprise': 0.0}}, {'gender': 'female', 'age': 18.0, 'emotion': {'anger': 0.0, 'contempt': 0.006, 'disgust': 0.0, 'fear': 0.0, 'happiness': 0.0, 'neutral': 0.981, 'sadness': 0.013, 'surprise': 0.0}}, {'gender': 'female', 'age': 18.0, 'emotion': {'anger': 0.0, 'contempt': 0.006, 'disgust': 0.0, 'fear': 0.0, 'happiness': 0.0, 'neutral': 0.981, 'sadness': 0.013, 'surprise': 0.0}}, {'gender': 'female', 'age': 18.0, 'emotion': {'anger': 0.0, 'contempt': 0.006, 'disgust': 0.0, 'fear': 0.0, 'happiness': 0.0, 'neutral': 0.981, 'sadness': 0.013, 'surprise': 0.0}}, {'gender': 'female', 'age': 18.0, 'emotion': {'anger': 0.0, 'contempt': 0.006, 'disgust': 0.0, 'fear': 0.0, 'happiness': 0.0, 'neutral': 0.981, 'sadness': 0.013, 'surprise': 0.0}}]\n"
     ]
    }
   ],
   "source": [
    "#pip install opencv-python\n",
    "\n",
    "# 거울기능 + 얼굴 캡쳐 후 감정분석 코드\n",
    "import cv2\n",
    "import datetime\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "import cognitive_face as CF\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# This key will serv/e all examples in this document.\n",
    "KEY = os.getenv(\"AZURE_KEY\")\n",
    "\n",
    "#노트북 카메라에서 영상을 읽어온다\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "CF.Key.set(KEY)\n",
    "\n",
    "BASE_URL = 'https://koreacentral.api.cognitive.microsoft.com/face/v1.0/' # 자신의 지역에 해당하는 URL\n",
    "CF.BaseUrl.set(BASE_URL)\n",
    "\n",
    "\n",
    "\n",
    "flag = 0\n",
    "i=0\n",
    "#얼굴 인식 캐스케이드 파일 읽는다\n",
    "face_cascade = cv2.CascadeClassifier('/Users/yejoonko/git/Project/smart_mirror_small_test/opencv-master/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "now = datetime.datetime.now().strftime(\"%d_%H-%M-%S\")\n",
    "arr=[1,2,3,4,5]\n",
    "imgArr = []\n",
    "emoArr = []\n",
    "emo_dic = {'anger': 0.0, 'contempt': 0.0, 'disgust': 0.0, 'fear': 0.0, 'happiness': 0.0, 'neutral': 0.0, 'sadness': 0.0, 'surprise': 0.0 }\n",
    "filePath=\"/Users/yejoonko/git/Project/smart_mirror_small_test/face/data/\"\n",
    "def removeAllFile(filePath):\n",
    "    if os.path.exists(filePath):\n",
    "        for file in os.scandir(filePath):\n",
    "            os.remove(file.path)\n",
    "        return \"Remove All File\"\n",
    "    else:\n",
    "        return \"Directory Not Found\"\n",
    "#removeAllFile(filePath);\n",
    "\n",
    "while(True):\n",
    "    # frame 별로 capture 한다\n",
    "    ret, frame = cap.read()\n",
    "    # 좌우 반전은 1, 상하반전은 0\n",
    "    frame = cv2.flip(frame,1)\n",
    "    cv2.imshow('webCamera',frame)\n",
    "    # 프레임이 제대로 읽어지지 않은 경우\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "        \n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #detectMultiScale (InputArray image, std::vector< Rect > &objects, double scaleFactor=1.1, int minNeighbors=3, int flags=0, Size minSize=Size(), Size maxSize=Size())\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.2, 5)\n",
    "    \n",
    "    while i < 6:\n",
    "        if len(faces)>0:\n",
    "            cv2.IMREAD_UNCHANGED\n",
    "            cv2.imwrite(\"/Users/yejoonko/git/Project/smart_mirror_small_test/face/data/\" + str(i) + \".png\", frame)\n",
    "            img_url = \"/Users/yejoonko/git/Project/smart_mirror_small_test/face/data/\" + str(i) + \".png\" # 이미지 파일의 경로\n",
    "            imgArr.append(img_url)\n",
    "            i+=1\n",
    "        \n",
    "        if i==6:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    if i==6 :\n",
    "        for j in imgArr :\n",
    "            faces = CF.face.detect(j,True,False,'age,gender,emotion') # 중요!\n",
    "        #webCamera라는 이름으로 실시간 화면을 보여준다.\n",
    "            for face in faces:\n",
    "#            print(face['faceAttributes']) # 터미널 창에 속성값들을 출력\n",
    "                emoArr.append(face['faceAttributes']['emotion'])\n",
    "        \n",
    "        for j in range(len(emoArr)) :\n",
    "            emo_dic['anger'] += emoArr[j]['anger'] \n",
    "            emo_dic['contempt'] += emoArr[j]['contempt']\n",
    "            emo_dic['disgust'] += emoArr[j]['disgust']\n",
    "            emo_dic['fear'] += emoArr[j]['fear']\n",
    "            emo_dic['happiness'] += emoArr[j]['happiness']\n",
    "            emo_dic['neutral'] += emoArr[j]['neutral']\n",
    "            emo_dic['sadness'] += emoArr[j]['sadness']\n",
    "            emo_dic['surprise'] += emoArr[j]['surprise']\n",
    "            \n",
    "        \n",
    "        i+=1\n",
    "    \n",
    "    \n",
    "\n",
    "    # q를 누르면 종료되도록 하는 코드이다.\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "# 메모리를 해제시켜준다.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
